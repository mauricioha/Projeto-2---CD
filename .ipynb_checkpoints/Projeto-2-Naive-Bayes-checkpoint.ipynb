{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o excel \n",
    "import pandas as pd\n",
    "\n",
    "lacta=pd.read_excel('tweets_lacta.xlsx')\n",
    "\n",
    "#Separando os tweets em tweets relevantes e irrelevantes\n",
    "relevant_tweets=lacta[lacta['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante']==1]\n",
    "\n",
    "irrelevant_tweets=lacta[lacta['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exceções - lista que contém elementos que devem ser retirados dos tweets para melhor análise \n",
    "excecoes=[':',';','[',']', '{','}','—','-','+','=','/','|', ')','_', '(','@','#', '?','.', '!', ' ',',']\n",
    "\n",
    "#Lista das palavras separadas de todos os tweets relevantes\n",
    "lista_palavras_relevant=[]\n",
    "\n",
    "for elemento in relevant_tweets['Treinamento']:\n",
    "    quebra=elemento.split()\n",
    "    for palavra in quebra:\n",
    "        lista_letra=list(palavra)\n",
    "        letras_corretas=[]\n",
    "        for letra in lista_letra:\n",
    "            if letra not in excecoes:\n",
    "                letras_corretas.append(letra)\n",
    "        palavra_limpa=''.join(letras_corretas)\n",
    "        lista_palavras_relevant.append(palavra_limpa)\n",
    "        \n",
    "\n",
    "#Lista das palavras separadas de todos os tweets irrelevantes\n",
    "lista_palavras_irrelevant=[]\n",
    "\n",
    "for elemento in irrelevant_tweets['Treinamento']:\n",
    "    quebra=elemento.split()\n",
    "    for palavra in quebra:\n",
    "        lista_letra=list(palavra)\n",
    "        letras_corretas=[]\n",
    "        for letra in lista_letra:\n",
    "            if letra not in excecoes:\n",
    "                letras_corretas.append(letra)\n",
    "        palavra_limpa=''.join(letras_corretas)\n",
    "        lista_palavras_irrelevant.append(palavra_limpa)\n",
    "\n",
    "        \n",
    "#Após a separação feita anteriormente, algumas strings ficaram vazias. Logo, o programa a seguir retira as palavras vazias.\n",
    "for palavra in lista_palavras_relevant:\n",
    "    if palavra=='':\n",
    "        lista_palavras_relevant.remove(palavra)\n",
    "\n",
    "for palavra in lista_palavras_irrelevant:\n",
    "    if palavra=='':\n",
    "        lista_palavras_irrelevant.remove(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo a contagem de cada palavra em relevantes e irrelevantes\n",
    "\n",
    "palavras_relevantes={}\n",
    "\n",
    "palavras_irrelevantes={}\n",
    "\n",
    "\n",
    "for palavra in lista_palavras_relevant:\n",
    "    if palavra not in palavras_relevantes:\n",
    "        palavras_relevantes[palavra]=2\n",
    "    else:\n",
    "        palavras_relevantes[palavra]+=1\n",
    "\n",
    "for palavra in lista_palavras_irrelevant:\n",
    "    if palavra not in palavras_irrelevantes:\n",
    "        palavras_irrelevantes[palavra]=2\n",
    "    else:\n",
    "        palavras_irrelevantes[palavra]+=1\n",
    "        \n",
    "#Total de palavras no excel de tweets relevantes\n",
    "total_relev=sum(palavras_relevantes.values())\n",
    "\n",
    "#Total de palavras no excel de tweets irrelevantes\n",
    "total_irrelev=sum(palavras_irrelevantes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade de um tweet ser relevante ou não\n",
    "p1=len(relevant_tweets)/len(lacta['Treinamento'])\n",
    "p0=len(irrelevant_tweets)/len(lacta['Treinamento'])\n",
    "\n",
    "#Encontrando a probabilidade de cada palavra\n",
    "for palavra in palavras_relevantes:\n",
    "    palavras_relevantes[palavra]=palavras_relevantes[palavra]/total_relev\n",
    "    \n",
    "for palavra in palavras_irrelevantes:\n",
    "    palavras_irrelevantes[palavra]=palavras_irrelevantes[palavra]/total_irrelev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função para o classificador\n",
    "\n",
    "def classificador(excel):\n",
    "    quebra_tudo=[]\n",
    "    classificacao=[]\n",
    "    for tweet in excel:\n",
    "        quebra=tweet.split()\n",
    "        for palavra in quebra:\n",
    "            lista_letra=list(palavra)\n",
    "            letras_corretas=[]\n",
    "            for letra in lista_letra:\n",
    "                if letra not in excecoes:\n",
    "                    letras_corretas.append(letra)\n",
    "            palavra_limpa=''.join(letras_corretas)\n",
    "            quebra_tudo.append(palavra_limpa)\n",
    "            p_r=0.11\n",
    "            p_i=0.89\n",
    "        for item in quebra_tudo:\n",
    "            p_r*=palavras_relevantes[item]\n",
    "            p_i*=palavras_irrelevantes[item]\n",
    "        if p_r>p_i:\n",
    "            classi=1\n",
    "        else:\n",
    "            classi=0\n",
    "        classificacao.append(classi)\n",
    "    return classificacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Treinamento'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a2354cee8e13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mteste\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets_lacta.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Treinamento'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassificador\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteste\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-8c35bb8c9c65>\u001b[0m in \u001b[0;36mclassificador\u001b[1;34m(excel)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mp_i\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.89\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquebra_tudo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mp_r\u001b[0m\u001b[1;33m*=\u001b[0m\u001b[0mpalavras_relevantes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mp_i\u001b[0m\u001b[1;33m*=\u001b[0m\u001b[0mpalavras_irrelevantes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mp_r\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mp_i\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Treinamento'"
     ]
    }
   ],
   "source": [
    "teste = pd.read_excel('tweets_lacta.xlsx',sheet_name='Treinamento')\n",
    "classificador(teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
