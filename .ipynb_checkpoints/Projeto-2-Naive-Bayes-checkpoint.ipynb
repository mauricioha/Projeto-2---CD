{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Insper - 2ºSemestre de Engenharia</b>\n",
    "\n",
    "Alunos: \n",
    "\n",
    "Fernando Elias Sanches \n",
    "\n",
    "Maurício Hiroki Ando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o excel \n",
    "import pandas as pd\n",
    "\n",
    "lacta=pd.read_excel('tweets_lacta.xlsx')\n",
    "\n",
    "#Separando os tweets em tweets relevantes e irrelevantes\n",
    "relevant_tweets=lacta[lacta['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante']==1]\n",
    "\n",
    "irrelevant_tweets=lacta[lacta['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exceções - lista que contém elementos que devem ser retirados dos tweets para melhor análise \n",
    "excecoes=[':',';','[',']', '{','}','—','-','+','=','/','|', ')','_', '(','#','?','.', '!', ' ',',','“','”','\\\\\\\\','\\n','\\t','*','','\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista das palavras separadas de todos os tweets relevantes\n",
    "lista_palavras_relevantes=[]\n",
    "\n",
    "for tweet in relevant_tweets['Treinamento']:\n",
    "    divide=tweet.split()\n",
    "    for palavra in divide:\n",
    "        if '@' not in palavra:\n",
    "            if 'https' not in palavra:\n",
    "                lista_letra=list(palavra)\n",
    "                letras_corretas=[]\n",
    "                for letra in lista_letra:\n",
    "                    if letra not in excecoes:\n",
    "                        letras_corretas.append(letra)\n",
    "                palavra_limpa=''.join(letras_corretas)\n",
    "                if palavra_limpa!='':\n",
    "                    lista_palavras_relevantes.append(palavra_limpa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista das palavras separadas de todos os tweets irrelevantes\n",
    "lista_palavras_irrelevantes=[]\n",
    "\n",
    "for tweet in irrelevant_tweets['Treinamento']:\n",
    "    divide=tweet.split()\n",
    "    for palavra in divide:\n",
    "        if '@' not in palavra:\n",
    "            if 'https' not in palavra:\n",
    "                lista_letra=list(palavra)\n",
    "                letras_corretas=[]\n",
    "                for letra in lista_letra:\n",
    "                    if letra not in excecoes:\n",
    "                        letras_corretas.append(letra)\n",
    "                palavra_limpa=''.join(letras_corretas)\n",
    "                if palavra_limpa!='':\n",
    "                    lista_palavras_irrelevantes.append(palavra_limpa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo a contagem de cada palavra em relevantes e irrelevantes\n",
    "\n",
    "palavras_relevantes={}\n",
    "\n",
    "palavras_irrelevantes={}\n",
    "\n",
    "\n",
    "for palavra in lista_palavras_relevantes:\n",
    "    if palavra not in palavras_relevantes:\n",
    "        palavras_relevantes[palavra]=2 #por conta do smoothing somou-se mais 1\n",
    "    else:\n",
    "        palavras_relevantes[palavra]+=1\n",
    "\n",
    "for word in lista_palavras_irrelevantes:\n",
    "    if word not in palavras_irrelevantes:\n",
    "        palavras_irrelevantes[word]=2 #por conta do smoothing somou-se mais 1\n",
    "    else:\n",
    "        palavras_irrelevantes[word]+=1\n",
    "        \n",
    "#Total de palavras no excel de tweets relevantes\n",
    "total_relev=sum(palavras_relevantes.values())\n",
    "\n",
    "#Total de palavras no excel de tweets irrelevantes\n",
    "total_irrelev=sum(palavras_irrelevantes.values())\n",
    "\n",
    "#União das duas, sem repetição\n",
    "lista_comum=list(palavras_relevantes.keys())+list(palavras_irrelevantes.keys())\n",
    "lista_sem_rep=set(lista_comum)\n",
    "length_lista=len(lista_sem_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11333333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilidade de um tweet ser relevante ou não\n",
    "p1=len(relevant_tweets)/len(lacta['Treinamento'])\n",
    "p0=len(irrelevant_tweets)/len(lacta['Treinamento'])\n",
    "\n",
    "#Encontrando a probabilidade de cada palavra\n",
    "for palavra in palavras_relevantes:\n",
    "    palavras_relevantes[palavra]=palavras_relevantes[palavra]/total_relev\n",
    "    \n",
    "for word in palavras_irrelevantes:\n",
    "    palavras_irrelevantes[word]=palavras_irrelevantes[word]/total_irrelev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função para o classificador\n",
    "\n",
    "def classificador(excel):\n",
    "    classificacao=[]\n",
    "    for tweet in excel['Teste']:\n",
    "        quebra_tudo=[]\n",
    "        divide=tweet.split()\n",
    "        p_r=p1\n",
    "        p_i=p0\n",
    "        for palavra in divide:\n",
    "            if '@' not in palavra:\n",
    "                if 'https' not in palavra:\n",
    "                    lista_letra=list(palavra)\n",
    "                    letras_corretas=[]\n",
    "                    for letra in lista_letra:\n",
    "                        if letra not in excecoes:\n",
    "                            letras_corretas.append(letra)\n",
    "                    palavra_limpa=''.join(letras_corretas)\n",
    "                    if palavra_limpa!='':\n",
    "                        quebra_tudo.append(palavra_limpa)\n",
    "        for item in quebra_tudo:\n",
    "            if item not in palavras_relevantes.keys() and item in palavras_irrelevantes.keys():\n",
    "                p_r*=1/(total_relev+length_lista)\n",
    "                p_i*=palavras_irrelevantes[item]\n",
    "            elif item in palavras_relevantes.keys() and item not in palavras_irrelevantes.keys():\n",
    "                p_i*=1/(total_irrelev+length_lista)\n",
    "                p_r*=palavras_relevantes[item]\n",
    "            elif item in palavras_relevantes.keys() and item in palavras_irrelevantes.keys():\n",
    "                p_r*=palavras_relevantes[item]\n",
    "                p_i*=palavras_irrelevantes[item]\n",
    "            else:\n",
    "                p_r*=1/(total_relev+length_lista)\n",
    "                p_i*=1/(total_irrelev+length_lista)\n",
    "        if p_r>p_i:\n",
    "            classi=1\n",
    "        else:\n",
    "            classi=0\n",
    "        classificacao.append(classi)\n",
    "    excel['Naive']=classificacao\n",
    "    excel.to_excel('excel_classificado.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teste = pd.read_excel('tweets_lacta.xlsx',sheet_name=\"Teste\")\n",
    "classificador(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos: 26. Sua porcentagem: 13.0%\n",
      "Negativos: 122. Sua porcentagem: 61.0%\n",
      "Falsos-negativos: 4. Sua porcentagem: 2.0%\n",
      "Falsos-positivos: 48. Sua porcentagem: 24.0%\n"
     ]
    }
   ],
   "source": [
    "#Esse programa é utilizado para contar o acerto de nosso classificador e sua porcentagem.\n",
    "a=pd.read_excel('excel_classificado.xlsx')\n",
    "a\n",
    "negativos=0\n",
    "positivos=0\n",
    "falsos_positivos=0\n",
    "falsos_negativos=0\n",
    "for n in range(len(a['Teste'])):\n",
    "    if a['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante'][n]==1 and a['Naive'][n]==1:\n",
    "        positivos+=1\n",
    "    elif a['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante'][n]==1 and a['Naive'][n]==0:\n",
    "        falsos_negativos+=1\n",
    "    elif a['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante'][n]==0 and a['Naive'][n]==1:\n",
    "        falsos_positivos+=1\n",
    "    else:\n",
    "        negativos+=1\n",
    "print(\"Positivos: {0}. Sua porcentagem: {1}%\".format(positivos,positivos*100/len(a['Teste'])))\n",
    "print(\"Negativos: {0}. Sua porcentagem: {1}%\".format(negativos,negativos*100/len(a['Teste'])))\n",
    "print(\"Falsos-negativos: {0}. Sua porcentagem: {1}%\".format(falsos_negativos,falsos_negativos*100/len(a['Teste'])))\n",
    "print(\"Falsos-positivos: {0}. Sua porcentagem: {1}%\".format(falsos_positivos,falsos_positivos*100/len(a['Teste'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Observando o resultado do teste, o índice de acertos do classificador é razoável, com um índice de acerto de 74%. No entanto, analisando ainda a base de 'Treinamento' dos tweets, a probabilidade de um tweet ser relevante é cerca de 11%, enquanto a probabilidade do tweet não ser relevante é de 89%. Logo, caso o classificador retornasse sempre 0, isto é, retornar que todo tweet é irrelevante, o índice de acertos do classificador seria 89%. Portanto, comparando o índice real de acertos que obtivemos com o classificador, com o caso em que o classificador sempre devolve 0, o índice real de acertos ainda é baixo. Com base nessas informações, provavelmente a empresa não nos contrataria, pois ela esperaria um índice de acerto maior que 89%. No entanto, podem ser feitas algumas alterações e melhoras no classificador para que a empresa possa se interessar e pensar num possível contrato. \n",
    "       Assim, para aumentar a eficâcia do classificador, poderíamos aumentar a base de dados analisados, isto é, analisar mais tweets, especificamente os tweets relevantes. Logo, é possível obter um melhor balanceamento entre tweets relevantes e irrelevantes, podendo obter um maior índice de acertos. Por exemplo, comparar 30 tweets relevantes com 270 irrelevantes é muito diferente de comparar 70 tweets, ou ainda 100 tweets com 200 tweets. Outra iteração possível para a melhoria do classificador, seria implementar outros tipos de filtros, como por exemplo, retirar palavras de duas letras que não mostram uma tendência clara de opinião, como por exemplo 'de', 'da', 'do'. Nesse caso, é necessário tomar muito cuidado para retirar palavra que, mesmo com duas palavras, tenham um significado mais tendencioso, como por exemplo, pronomes de tratamento 'tu' ou 'vc', ou até palavrões, que não será citado aqui. Esses tipos de palavras podem até demonstrar se o cliente está satisfeito ou não com a marca/produto. Seria possível também separar os emojis e tratá-los de forma individual pois cada emoji expressa uma emoção, e o classificador atual classifica grupos inteiros de emoji, isto é, \":D\" é diferente de \":D:D\", ou ainda, 'T_T ^w^' é diferente de 'T_T' '^w^'. Uma última iteração que poderia ser feito, é lidar com tweets sarcásticos ou com dupla negação. Isso também pode ser melhorado, fazendo uma futura iteração para o classificador. Para fazer com que o classificador detecte sarcasmo, podemos criar um banco de dados com tweets seguidos da hashtag \"#sarcasmo\" e aplicá-lo ao Naive Bayes (http://www.lewisgavin.co.uk/Sarcasm-Detector/). Para essas iterações, podemos nos basear em conhecimento próprio, mas podemos, também, nos basear em alguns sites da web, como o stackoverflow e projetos já existentes sobre naive bayes.\n",
    "       Analisando os resultados um pouco mais a fundo, nota-se que a maior taxa de erro está no \"Falsos-positivos\" representando 24% do resultado dado pelo classificador, enquanto os \"Falsos-negativos\" representam 2%. Essa discrepância no banco de dados mostra que o classificador não consegue classificar os tweets relevantes de forma correta. \n",
    "       Com relação às amostras de um tweet, o classificador não poderia ser usado para gerar mais amostras pois se trata apenas de um programa que recebe um arquivo com vários tweets e retorna se os tweets são relevantes ou irrelevantes, mas não cria nenhum outro tweet. Caso ele gerasse amostras, ele pegaria palavras aleatórias do banco de dados e criaria um tweet sem sentido, o que não seria relevante a empresa. Pode-se ter até mesmo todas as palavras do dicionário, mas o programa poderia retornar uma frase como \"Gosto peixe ela azul uva escola de\". Por conta disso é que acreditamos que o classificador não poderia gerar mais amostras de tweets.\n",
    "       Finalmente, pensando fora do contexto de empresas e análise de que um tweet pode ser relevante ou não, o classificador Naive Bayes poderia ser utilizado também para desenvolvimento de Inteligência Artificial. Seria possível fazer uma pergunta para um sistema de Inteligência Artificial, que passaria por um processo de classificação e retornaria uma resposta à pergunta. Outra possível aplicação seria para classificar dados de um objeto fornecidos por um usuário, como formato e as dimensões do objeto; e o classificador retornaria qual objeto possui tais características."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
