{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o excel \n",
    "import pandas as pd\n",
    "\n",
    "lacta=pd.read_excel('tweets_lacta.xlsx')\n",
    "\n",
    "#Separando os tweets em tweets relevantes e irrelevantes\n",
    "relevant_tweets=lacta[lacta['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante']==1]\n",
    "\n",
    "irrelevant_tweets=lacta[lacta['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exceções - lista que contém elementos que devem ser retirados dos tweets para melhor análise \n",
    "excecoes=[':',';','[',']', '{','}','—','-','+','=','/','|', ')','_', '(','#','?','.', '!', ' ',',','“','”','\\\\\\\\']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nunca',\n",
       " 'bombom',\n",
       " 'tão',\n",
       " 'mal',\n",
       " 'embalado',\n",
       " 'que',\n",
       " 'que',\n",
       " 'acontecendo',\n",
       " 'com',\n",
       " 'seus',\n",
       " 'bombons',\n",
       " 'httpstcohrfikrguxl',\n",
       " 'aquele',\n",
       " 'sonho',\n",
       " 'valsa',\n",
       " 'com',\n",
       " 'larva',\n",
       " 'nosso',\n",
       " 'cada',\n",
       " 'dia',\n",
       " 'httpstcovonzdpywbz',\n",
       " 'mas',\n",
       " 'lolo',\n",
       " 'nao',\n",
       " 'aquele',\n",
       " 'bombom',\n",
       " 'lacta',\n",
       " 'que',\n",
       " 'ngm',\n",
       " 'gosta',\n",
       " 'pelo',\n",
       " 'amor',\n",
       " 'deus',\n",
       " 'tirem',\n",
       " 'pouco',\n",
       " 'açucar',\n",
       " 'das',\n",
       " 'barras',\n",
       " 'chocolate',\n",
       " 'comi',\n",
       " 'pedaço',\n",
       " 'meu',\n",
       " 'lacta',\n",
       " 'diamante',\n",
       " 'negro',\n",
       " 'misto',\n",
       " 'chegou',\n",
       " 'doer',\n",
       " 'olhos',\n",
       " 'fechar',\n",
       " 'garganta',\n",
       " 'tão',\n",
       " 'doce',\n",
       " 'um',\n",
       " 'conselho',\n",
       " 'um',\n",
       " 'consumidor',\n",
       " 'impressionada',\n",
       " 'como',\n",
       " 'cholates',\n",
       " 'perderam',\n",
       " 'qualidade',\n",
       " 'lacta',\n",
       " 'fosse',\n",
       " 'aqueles',\n",
       " 'chocolates',\n",
       " 'finos',\n",
       " 'veganos',\n",
       " 'até',\n",
       " 'entenderia',\n",
       " 'melhor',\n",
       " 'chocolate',\n",
       " 'branco',\n",
       " 'somente',\n",
       " 'lacta',\n",
       " 'resto',\n",
       " 'horrível',\n",
       " 'pq',\n",
       " 'estão',\n",
       " 'diminuindo',\n",
       " 'tanto',\n",
       " 'barra',\n",
       " 'chocolate',\n",
       " 'preço',\n",
       " 'igual',\n",
       " 'sem',\n",
       " 'papinho',\n",
       " 'furado',\n",
       " 'somos',\n",
       " 'consumidores',\n",
       " 'não',\n",
       " 'otários',\n",
       " 'marcas',\n",
       " 'que',\n",
       " 'você',\n",
       " 'mudaria',\n",
       " 'seu',\n",
       " 'país',\n",
       " 'barra',\n",
       " 'chocolate',\n",
       " 'lacta',\n",
       " 'oreo',\n",
       " '135g',\n",
       " 'r$199',\n",
       " 'httpstcoczecdxjked',\n",
       " 'chocolates',\n",
       " 'lacta',\n",
       " 'diminuírem',\n",
       " 'ainda',\n",
       " 'mais',\n",
       " 'tamanho',\n",
       " 'valerá',\n",
       " 'mais',\n",
       " 'pena',\n",
       " 'comprar',\n",
       " 'uma',\n",
       " 'caixa',\n",
       " 'bombom',\n",
       " 'porque',\n",
       " 'estão',\n",
       " 'quase',\n",
       " 'mesmo',\n",
       " 'tamanho',\n",
       " 'acabei',\n",
       " 'comprar',\n",
       " 'abrir',\n",
       " 'sonho',\n",
       " 'valsa',\n",
       " 'pra',\n",
       " 'comer',\n",
       " 'está',\n",
       " 'cheio',\n",
       " 'larvas',\n",
       " 'que',\n",
       " 'bacana',\n",
       " 'gente',\n",
       " 'compra',\n",
       " 'bis',\n",
       " 'ele',\n",
       " 'vem',\n",
       " 'aberto',\n",
       " 'eai',\n",
       " 'httpstcohfbxvadxxr',\n",
       " 'diminuiu',\n",
       " 'uma',\n",
       " 'fileirinha',\n",
       " 'tamanho',\n",
       " 'barra',\n",
       " 'chocolate',\n",
       " 'ainda',\n",
       " 'teve',\n",
       " 'audácia',\n",
       " 'colocar',\n",
       " 'embalagem',\n",
       " 'feito',\n",
       " 'pra',\n",
       " 'você',\n",
       " 'pelo',\n",
       " 'mesmo',\n",
       " 'preço',\n",
       " 'um',\n",
       " 'dia',\n",
       " 'passou',\n",
       " 'aínda',\n",
       " 'tentando',\n",
       " 'abrir',\n",
       " 'embalagem',\n",
       " 'barra',\n",
       " 'chocolate',\n",
       " 'lacta',\n",
       " 'até',\n",
       " 'contentaria',\n",
       " 'com',\n",
       " '120g',\n",
       " '@fernandocontart',\n",
       " 'fernando',\n",
       " 'você',\n",
       " 'pode',\n",
       " 'entrar',\n",
       " 'contato',\n",
       " 'pelo',\n",
       " 'sac',\n",
       " 'também',\n",
       " 'preferir',\n",
       " 'para',\n",
       " 'entendermos',\n",
       " 'melhor',\n",
       " 'sua',\n",
       " 'situação',\n",
       " 'através',\n",
       " 'telefone',\n",
       " '0800',\n",
       " '704',\n",
       " '1940',\n",
       " 'agradecemos',\n",
       " 'seu',\n",
       " 'contato',\n",
       " 'amanda',\n",
       " 'expectativa',\n",
       " 'realidade',\n",
       " 'como',\n",
       " 'faz',\n",
       " '',\n",
       " 'lacta',\n",
       " 'httpstcou29qaaawvk',\n",
       " 'nunca',\n",
       " 'perdoa',\n",
       " 'lacta',\n",
       " 'por',\n",
       " 'parado',\n",
       " 'vende',\n",
       " 'shot',\n",
       " 'choco',\n",
       " 'branco',\n",
       " 'comprei',\n",
       " 'duas',\n",
       " 'caixas',\n",
       " 'bombom',\n",
       " 'não',\n",
       " 'veio',\n",
       " 'nenhum',\n",
       " 'bis',\n",
       " 'oreo',\n",
       " 'nem',\n",
       " 'lancy',\n",
       " 'sendo',\n",
       " 'que',\n",
       " 'pra',\n",
       " 'foder',\n",
       " 'hein',\n",
       " 'httpstcogsaagumase',\n",
       " 'to',\n",
       " 'triste',\n",
       " 'com',\n",
       " 'vcs',\n",
       " 'comprei',\n",
       " 'uma',\n",
       " 'caixa',\n",
       " 'não',\n",
       " 'veio',\n",
       " 'meu',\n",
       " 'predileeeeeeeeeeto',\n",
       " 'dentro',\n",
       " 'vou',\n",
       " 'chorarrip',\n",
       " 'laka',\n",
       " 'caixa',\n",
       " '&lt3',\n",
       " 'quando',\n",
       " 'vai',\n",
       " 'chegar',\n",
       " 'bis',\n",
       " 'black',\n",
       " 'franca',\n",
       " 'precisoooo',\n",
       " 'não',\n",
       " 'aguento',\n",
       " 'mais',\n",
       " 'ver',\n",
       " 'stories',\n",
       " 'pessoal',\n",
       " 'sampa',\n",
       " 'eu',\n",
       " 'não',\n",
       " 'poder',\n",
       " 'comer',\n",
       " 'po',\n",
       " 'sacanagema',\n",
       " 'caixa',\n",
       " 'bis',\n",
       " 'diminuiu',\n",
       " 'deviam',\n",
       " 'aumentar',\n",
       " 'isso',\n",
       " 'sim',\n",
       " 'que',\n",
       " 'preço',\n",
       " 'permanece',\n",
       " 'mesmo',\n",
       " '@thehmep',\n",
       " 'se',\n",
       " 'quer',\n",
       " 'aumentar',\n",
       " 'preço',\n",
       " 'aumenta',\n",
       " 'culpa',\n",
       " 'governo',\n",
       " 'economia',\n",
       " 'inflação',\n",
       " 'mas',\n",
       " 'tentar',\n",
       " 'fazer',\n",
       " 'consumidor',\n",
       " 'idiota',\n",
       " 'foda',\n",
       " '@lacta',\n",
       " 'querida',\n",
       " 'onde',\n",
       " 'prêmios',\n",
       " '500',\n",
       " 'realetas',\n",
       " 'serão',\n",
       " 'divulgados',\n",
       " 'boa',\n",
       " 'noite',\n",
       " 'pra',\n",
       " 'quem',\n",
       " 'pagou',\n",
       " 'reais',\n",
       " 'numa',\n",
       " 'barra',\n",
       " '@lacta',\n",
       " 'dps',\n",
       " 'viu',\n",
       " 'que',\n",
       " 'era',\n",
       " 'uma',\n",
       " 'barra',\n",
       " '90g',\n",
       " 'não',\n",
       " 'uma',\n",
       " '115',\n",
       " '120g',\n",
       " 'triste',\n",
       " 'estou',\n",
       " 'muito',\n",
       " 'indignada',\n",
       " 'com',\n",
       " 'lacta',\n",
       " 'tiraram',\n",
       " 'lancy',\n",
       " 'shot',\n",
       " 'caixa',\n",
       " 'bombom',\n",
       " 'deles',\n",
       " 'meus',\n",
       " 'chocolates',\n",
       " 'favorito',\n",
       " 'droga',\n",
       " 'vdd',\n",
       " 'melhor',\n",
       " 'caixa',\n",
       " 'bombom',\n",
       " 'seria',\n",
       " 'aquela',\n",
       " 'que',\n",
       " 'pode',\n",
       " 'escolher',\n",
       " 'que',\n",
       " 'por',\n",
       " 'tipo',\n",
       " 'pegar',\n",
       " 'sensação',\n",
       " 'galak',\n",
       " 'lollo',\n",
       " 'prestígio',\n",
       " 'nestlé',\n",
       " 'lacta',\n",
       " 'diamante',\n",
       " 'negro',\n",
       " 'aquele',\n",
       " 'confete',\n",
       " 'lacta',\n",
       " 'da',\n",
       " 'garoto',\n",
       " 'review',\n",
       " 'sobre',\n",
       " 'chocolate',\n",
       " 'ontem',\n",
       " 'comprei',\n",
       " 'uma',\n",
       " 'barra',\n",
       " 'lacta',\n",
       " 'chocolate',\n",
       " 'branco',\n",
       " 'sabor',\n",
       " 'caramelo',\n",
       " 'salgado',\n",
       " 'coco',\n",
       " 'só',\n",
       " 'tem',\n",
       " 'nome',\n",
       " 'pra',\n",
       " 'pegar',\n",
       " 'besta',\n",
       " 'barra',\n",
       " 'só',\n",
       " 'chocolate',\n",
       " 'branco',\n",
       " 'mesmo',\n",
       " 'barras',\n",
       " 'chocolate',\n",
       " 'da',\n",
       " 'nestlélacta',\n",
       " 'estão',\n",
       " 'cada',\n",
       " 'vez',\n",
       " 'menores',\n",
       " 'absurdo',\n",
       " '@lacta',\n",
       " 'saudades',\n",
       " 'quando',\n",
       " 'o',\n",
       " 'chocolate',\n",
       " 'derretia',\n",
       " 'boca',\n",
       " 'vinha',\n",
       " 'embrulhado',\n",
       " 'papel',\n",
       " 'alumínio',\n",
       " 'o',\n",
       " 'diamante',\n",
       " 'negro',\n",
       " 'tinha',\n",
       " 'um',\n",
       " 'sabor',\n",
       " 'especial',\n",
       " 'hoje',\n",
       " 'dia',\n",
       " 'duro',\n",
       " 'sem',\n",
       " 'sabor',\n",
       " 'nunca',\n",
       " 'pensei',\n",
       " 'que',\n",
       " 'diria',\n",
       " 'isso',\n",
       " 'massss',\n",
       " 'hersheys',\n",
       " 'superando',\n",
       " 'lacta',\n",
       " 'quesito',\n",
       " 'barra',\n",
       " '@lacta',\n",
       " 'boa',\n",
       " 'tarde',\n",
       " 'ganhei',\n",
       " 'promoção',\n",
       " '500',\n",
       " 'reais',\n",
       " 'amem',\n",
       " 'venci',\n",
       " 'vida',\n",
       " 'kkk',\n",
       " 'mandei',\n",
       " 'os',\n",
       " 'documentos',\n",
       " 'solicitados',\n",
       " 'por',\n",
       " 'email',\n",
       " 'mas',\n",
       " 'ninguém',\n",
       " 'confirmou',\n",
       " 'o',\n",
       " 'recebimento',\n",
       " 'poderia',\n",
       " 'verificar',\n",
       " 'só',\n",
       " 'barras',\n",
       " 'da',\n",
       " 'lacta',\n",
       " 'sao',\n",
       " 'acima',\n",
       " '100g',\n",
       " 'mas',\n",
       " 'msm',\n",
       " 'assim',\n",
       " 'quase',\n",
       " 'conto',\n",
       " '',\n",
       " 'nao',\n",
       " 'rola',\n",
       " 'coe',\n",
       " 'porque',\n",
       " 'vocês',\n",
       " 'diminuíram',\n",
       " 'o',\n",
       " 'amandita',\n",
       " '@lacta']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lista das palavras separadas de todos os tweets relevantes\n",
    "lista_palavras_relevantes=[]\n",
    "\n",
    "for elemento in relevant_tweets['Treinamento']:\n",
    "    quebra=elemento.split()\n",
    "    for palavra in quebra:\n",
    "        lista_letra=list(palavra)\n",
    "        letras_corretas=[]\n",
    "        for letra in lista_letra:\n",
    "            if letra not in excecoes:\n",
    "                letras_corretas.append(letra)\n",
    "        palavra_limpa=''.join(letras_corretas)\n",
    "        lista_palavras_relevantes.append(palavra_limpa)\n",
    "    \n",
    "#Após a separação feita anteriormente, algumas strings ficaram vazias. Logo, o programa a seguir retira as palavras vazias.\n",
    "for word in lista_palavras_relevantes:\n",
    "    if word==('') or len(word)<=2 or '@' in word:\n",
    "        lista_palavras_relevantes.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "T\n",
      "T\n",
      "T\n",
      "T\n",
      "T\n",
      "T\n"
     ]
    }
   ],
   "source": [
    "#Lista das palavras separadas de todos os tweets irrelevantes\n",
    "lista_palavras_irrelevantes=[]\n",
    "\n",
    "for e in irrelevant_tweets['Treinamento']:\n",
    "    queb=e.split()\n",
    "    for word in queb:\n",
    "        letter_list=list(word)\n",
    "        correct_words=[]\n",
    "        for letter in letter_list:\n",
    "            if letter not in excecoes:\n",
    "                correct_words.append(letter)\n",
    "        clean_word=''.join(correct_words)\n",
    "        lista_palavras_irrelevantes.append(clean_word)\n",
    "\n",
    "        \n",
    "#Após a separação feita anteriormente, algumas strings ficaram vazias. Logo, o programa a seguir retira as palavras vazias.\n",
    "for p in lista_palavras_irrelevantes:\n",
    "    if p==('') or len(p)<=2:\n",
    "        lista_palavras_irrelevantes.remove(p)\n",
    "    elif '@' in p:\n",
    "        lista_palavras_irrelevantes.remove(p)\n",
    "for novo in lista_palavras_relevantes:\n",
    "    if '@' in novo:\n",
    "        print('T')\n",
    "        lista_palavras_relevantes.remove(novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo a contagem de cada palavra em relevantes e irrelevantes\n",
    "\n",
    "palavras_relevantes={}\n",
    "\n",
    "palavras_irrelevantes={}\n",
    "\n",
    "\n",
    "for palavra in lista_palavras_relevantes:\n",
    "    if palavra not in palavras_relevantes:\n",
    "        palavras_relevantes[palavra]=2\n",
    "    else:\n",
    "        palavras_relevantes[palavra]+=1\n",
    "\n",
    "for palavra in lista_palavras_irrelevantes:\n",
    "    if palavra not in palavras_irrelevantes:\n",
    "        palavras_irrelevantes[palavra]=2\n",
    "    else:\n",
    "        palavras_irrelevantes[palavra]+=1\n",
    "        \n",
    "#Total de palavras no excel de tweets relevantes\n",
    "total_relev=sum(palavras_relevantes.values())\n",
    "\n",
    "#Total de palavras no excel de tweets irrelevantes\n",
    "total_irrelev=sum(palavras_irrelevantes.values())\n",
    "\n",
    "#União das duas, sem repetição\n",
    "lista_comum=list(palavras_relevantes.keys())+list(palavras_irrelevantes.keys())\n",
    "lista_sem_rep=set(lista_comum)\n",
    "length_lista=len(lista_sem_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade de um tweet ser relevante ou não\n",
    "p1=len(relevant_tweets)/len(lacta['Treinamento'])\n",
    "p0=len(irrelevant_tweets)/len(lacta['Treinamento'])\n",
    "\n",
    "#Encontrando a probabilidade de cada palavra\n",
    "for palavra in palavras_relevantes:\n",
    "    palavras_relevantes[palavra]=palavras_relevantes[palavra]/total_relev\n",
    "    \n",
    "for palavra in palavras_irrelevantes:\n",
    "    palavras_irrelevantes[palavra]=palavras_irrelevantes[palavra]/total_irrelev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função para o classificador\n",
    "\n",
    "def classificador(excel):\n",
    "    classificacao=[]\n",
    "    for tweet in excel['Teste']:\n",
    "        quebra_tudo=[]\n",
    "        quebra=tweet.split()\n",
    "        p_r=p1\n",
    "        p_i=p0\n",
    "        for palavra in quebra:\n",
    "            lista_letra=list(palavra)\n",
    "            letras_corretas=[]\n",
    "            for letra in lista_letra:\n",
    "                if letra not in excecoes:\n",
    "                    letras_corretas.append(letra)\n",
    "            palavra_limpa=''.join(letras_corretas)\n",
    "            quebra_tudo.append(palavra_limpa)\n",
    "        for item in quebra_tudo:\n",
    "            if item not in palavras_relevantes.keys() and item in palavras_irrelevantes.keys():\n",
    "                p_r*=1/(total_relev+length_lista)\n",
    "                p_i*=palavras_irrelevantes[item]\n",
    "            elif item in palavras_relevantes.keys() and item not in palavras_irrelevantes.keys():\n",
    "                p_i*=1/(total_irrelev+length_lista)\n",
    "                p_r*=palavras_relevantes[item]\n",
    "            elif item in palavras_relevantes.keys() and item in palavras_irrelevantes.keys():\n",
    "                p_r*=palavras_relevantes[item]\n",
    "                p_i*=palavras_irrelevantes[item]\n",
    "            else:\n",
    "                p_r*=1/(total_relev+length_lista)\n",
    "                p_i*=1/(total_irrelev+length_lista)\n",
    "        if p_r>p_i:\n",
    "            classi=1\n",
    "        else:\n",
    "            classi=0\n",
    "        classificacao.append(classi)\n",
    "    excel['Naive']=classificacao\n",
    "    excel.to_excel('excel_classificado.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teste = pd.read_excel('tweets_lacta.xlsx',sheet_name=\"Teste\")\n",
    "classificador(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos: 28, 14.0%\n",
      "Negativos: 108, 54.0%\n",
      "Falsos-negativos: 2, 1.0%\n",
      "Falsos-positivos: 62, 31.0%\n"
     ]
    }
   ],
   "source": [
    "a=pd.read_excel('Up.xlsx')\n",
    "a\n",
    "negativos=0\n",
    "positivos=0\n",
    "falsos_positivos=0\n",
    "falsos_negativos=0\n",
    "for n in range(len(a['Teste'])):\n",
    "    if a['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante'][n]==1 and a['Naive'][n]==1:\n",
    "        positivos+=1\n",
    "    elif a['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante'][n]==1 and a['Naive'][n]==0:\n",
    "        falsos_negativos+=1\n",
    "    elif a['Classificador - 1 para relevante(críticas/sugestões) para a empresa e 0 para não relevante'][n]==0 and a['Naive'][n]==1:\n",
    "        falsos_positivos+=1\n",
    "    else:\n",
    "        negativos+=1\n",
    "print(\"Positivos: {0}, {1}%\".format(positivos,(positivos*100/len(a['Teste']))))\n",
    "print(\"Negativos: {0}, {1}%\".format(negativos,(negativos*100/len(a['Teste']))))\n",
    "print(\"Falsos-negativos: {0}, {1}%\".format(falsos_negativos,(falsos_negativos*100/len(a['Teste']))))\n",
    "print(\"Falsos-positivos: {0}, {1}%\".format(falsos_positivos,(falsos_positivos*100/len(a['Teste']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
